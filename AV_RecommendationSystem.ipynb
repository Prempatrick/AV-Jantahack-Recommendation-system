{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "69WFJHJVFQ6L",
    "outputId": "111c72d8-491b-4c04-aa90-5b21ce303807"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,Input,BatchNormalization,TimeDistributed,CuDNNGRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "#from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iD7ii4S-FVNz"
   },
   "outputs": [],
   "source": [
    "    # Load data\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    # Create labels\n",
    "    label = train[train.challenge_sequence > 10][['user_id','challenge']]\n",
    "    label.rename(columns={'challenge':'label'},inplace=True)\n",
    "    \n",
    "    # Treat the sequence of challenges as text\n",
    "    df = train[train.challenge_sequence <= 10].groupby('user_id').challenge.aggregate(lambda x: ' '.join(x)).reset_index()\n",
    "    \n",
    "    # Merge Labels\n",
    "    df = df.merge(label)\n",
    "    \n",
    "    # Validation split for early stopping\n",
    "    df_train, df_validation = train_test_split(df.sample(frac=1,random_state=123), test_size=0.05, random_state=123)\n",
    "    \n",
    "    # Load all the challenges\n",
    "    challenges = pd.read_csv('challenge_data.csv')\n",
    "    \n",
    "    # Encode challenges\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(challenges['challenge_ID'])\n",
    "    df_train['brand_id_encoded'] = encoder.transform(df_train.label)\n",
    "    df_validation['brand_id_encoded'] = encoder.transform(df_validation.label)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df_train['challenge'])\n",
    "    \n",
    "    # Constants\n",
    "    NB_WORDS = len(tokenizer.word_index)\n",
    "    MAX_SEQUENCE_LENGTH = 10\n",
    "    N_CATEGORIES = challenges.shape[0]\n",
    "    \n",
    "    # Create sequences\n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['challenge'])\n",
    "    sequences_validation = tokenizer.texts_to_sequences(df_validation['challenge'])\n",
    "    \n",
    "    # Pad sequences\n",
    "    x_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    x_validation = pad_sequences(sequences_validation, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    \n",
    "    # Set Labels\n",
    "    y_train = df_train['brand_id_encoded'].values\n",
    "    y_validation= df_validation['brand_id_encoded'].values\n",
    "\n",
    "    # Test preprocessing\n",
    "    def padding(text):\n",
    "        return pad_sequences(tokenizer.texts_to_sequences(text), maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    test_text = test[test.challenge_sequence <= 10].groupby('user_id').challenge.aggregate(lambda x: ' '.join(x)).reset_index()\n",
    "    x_test = padding(test_text.challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILLwaSlyJYjY"
   },
   "outputs": [],
   "source": [
    "    # Model callbacks\n",
    "    path = 'best_model_weights'\n",
    "    es_callback = EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "    mc_callback = ModelCheckpoint('{}.hdf5'.format(path), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "    lr_callback = ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.001)\n",
    "    callbacks = [lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68aCvG6SGJp4"
   },
   "outputs": [],
   "source": [
    "    # NN architecture\n",
    "    def get_model(path='',lr=0.005,dim):\n",
    "        adam = Adam(lr=lr)\n",
    "        inp = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "        x = Embedding(NB_WORDS,dim)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(LSTM(dim, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(N_CATEGORIES, activation=\"softmax\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        \n",
    "        if path != '':\n",
    "            model.load_weights(path)\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    # Initialize the model\n",
    "    model0 = get_model(dim=256)\n",
    "    model2 = get_model(dim=512)\n",
    "    model4 = get_model(dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T-KOwE7F9W_5",
    "outputId": "950d68c9-9192-4055-cfd6-7bbf38bc83cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 198166 samples, validate on 10430 samples\n",
      "Epoch 1/100\n",
      "198166/198166 [==============================] - 23s 114us/step - loss: 5.6067 - accuracy: 0.0401 - val_loss: 5.3442 - val_accuracy: 0.0397\n",
      "Epoch 2/100\n",
      "198166/198166 [==============================] - 21s 105us/step - loss: 4.9006 - accuracy: 0.0617 - val_loss: 4.7239 - val_accuracy: 0.0697\n",
      "Epoch 3/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 4.6454 - accuracy: 0.0746 - val_loss: 4.5662 - val_accuracy: 0.0805\n",
      "Epoch 4/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 4.4735 - accuracy: 0.0844 - val_loss: 4.5107 - val_accuracy: 0.0795\n",
      "Epoch 5/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 4.3367 - accuracy: 0.0948 - val_loss: 4.4698 - val_accuracy: 0.0769\n",
      "Epoch 6/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 4.2332 - accuracy: 0.1011 - val_loss: 4.4633 - val_accuracy: 0.0789\n",
      "Epoch 7/100\n",
      "198166/198166 [==============================] - 19s 98us/step - loss: 4.1531 - accuracy: 0.1070 - val_loss: 4.4641 - val_accuracy: 0.0782\n",
      "Epoch 8/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 4.0845 - accuracy: 0.1110 - val_loss: 4.4621 - val_accuracy: 0.0767\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 9/100\n",
      "198166/198166 [==============================] - 19s 98us/step - loss: 3.9027 - accuracy: 0.1285 - val_loss: 4.4399 - val_accuracy: 0.0749\n",
      "Epoch 10/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.8320 - accuracy: 0.1354 - val_loss: 4.4378 - val_accuracy: 0.0715\n",
      "Epoch 11/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.7898 - accuracy: 0.1386 - val_loss: 4.4472 - val_accuracy: 0.0727\n",
      "Epoch 12/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.7626 - accuracy: 0.1407 - val_loss: 4.4511 - val_accuracy: 0.0757\n",
      "Epoch 13/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.7282 - accuracy: 0.1439 - val_loss: 4.4572 - val_accuracy: 0.0736\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 14/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.6426 - accuracy: 0.1534 - val_loss: 4.4632 - val_accuracy: 0.0713\n",
      "Epoch 15/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.6094 - accuracy: 0.1562 - val_loss: 4.4724 - val_accuracy: 0.0680\n",
      "Epoch 16/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.5843 - accuracy: 0.1592 - val_loss: 4.4772 - val_accuracy: 0.0663\n",
      "Epoch 17/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.5746 - accuracy: 0.1590 - val_loss: 4.4844 - val_accuracy: 0.0663\n",
      "Epoch 18/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.5557 - accuracy: 0.1611 - val_loss: 4.4915 - val_accuracy: 0.0663\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 19/100\n",
      "198166/198166 [==============================] - 19s 97us/step - loss: 3.5345 - accuracy: 0.1639 - val_loss: 4.4969 - val_accuracy: 0.0655\n",
      "Epoch 20/100\n",
      "198166/198166 [==============================] - 19s 97us/step - loss: 3.5188 - accuracy: 0.1661 - val_loss: 4.5005 - val_accuracy: 0.0643\n",
      "Epoch 21/100\n",
      "198166/198166 [==============================] - 19s 98us/step - loss: 3.5111 - accuracy: 0.1662 - val_loss: 4.5030 - val_accuracy: 0.0654\n",
      "Epoch 22/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.4984 - accuracy: 0.1672 - val_loss: 4.5069 - val_accuracy: 0.0646\n",
      "Epoch 23/100\n",
      "198166/198166 [==============================] - 21s 105us/step - loss: 3.4905 - accuracy: 0.1678 - val_loss: 4.5155 - val_accuracy: 0.0637\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 24/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.4811 - accuracy: 0.1685 - val_loss: 4.5191 - val_accuracy: 0.0659\n",
      "Epoch 25/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.4737 - accuracy: 0.1700 - val_loss: 4.5212 - val_accuracy: 0.0664\n",
      "Epoch 26/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.4664 - accuracy: 0.1693 - val_loss: 4.5266 - val_accuracy: 0.0663\n",
      "Epoch 27/100\n",
      "198166/198166 [==============================] - 19s 98us/step - loss: 3.4576 - accuracy: 0.1712 - val_loss: 4.5266 - val_accuracy: 0.0635\n",
      "Epoch 28/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.4509 - accuracy: 0.1701 - val_loss: 4.5320 - val_accuracy: 0.0646\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 29/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.4440 - accuracy: 0.1706 - val_loss: 4.5392 - val_accuracy: 0.0633\n",
      "Epoch 30/100\n",
      "198166/198166 [==============================] - 20s 98us/step - loss: 3.4378 - accuracy: 0.1730 - val_loss: 4.5379 - val_accuracy: 0.0624\n",
      "Epoch 31/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.4334 - accuracy: 0.1716 - val_loss: 4.5445 - val_accuracy: 0.0602\n",
      "Epoch 32/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.4310 - accuracy: 0.1716 - val_loss: 4.5481 - val_accuracy: 0.0624\n",
      "Epoch 33/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.4224 - accuracy: 0.1728 - val_loss: 4.5486 - val_accuracy: 0.0610\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 34/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.4125 - accuracy: 0.1761 - val_loss: 4.5539 - val_accuracy: 0.0637\n",
      "Epoch 35/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.4092 - accuracy: 0.1750 - val_loss: 4.5574 - val_accuracy: 0.0616\n",
      "Epoch 36/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.4059 - accuracy: 0.1761 - val_loss: 4.5621 - val_accuracy: 0.0606\n",
      "Epoch 37/100\n",
      "198166/198166 [==============================] - 20s 98us/step - loss: 3.4000 - accuracy: 0.1753 - val_loss: 4.5658 - val_accuracy: 0.0621\n",
      "Epoch 38/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.3971 - accuracy: 0.1743 - val_loss: 4.5692 - val_accuracy: 0.0592\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 39/100\n",
      "198166/198166 [==============================] - 19s 98us/step - loss: 3.3907 - accuracy: 0.1778 - val_loss: 4.5764 - val_accuracy: 0.0590\n",
      "Epoch 40/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3892 - accuracy: 0.1770 - val_loss: 4.5773 - val_accuracy: 0.0604\n",
      "Epoch 41/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3816 - accuracy: 0.1760 - val_loss: 4.5823 - val_accuracy: 0.0593\n",
      "Epoch 42/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.3806 - accuracy: 0.1754 - val_loss: 4.5906 - val_accuracy: 0.0588\n",
      "Epoch 43/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.3721 - accuracy: 0.1790 - val_loss: 4.5949 - val_accuracy: 0.0596\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 44/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.3679 - accuracy: 0.1789 - val_loss: 4.5970 - val_accuracy: 0.0585\n",
      "Epoch 45/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3628 - accuracy: 0.1783 - val_loss: 4.5996 - val_accuracy: 0.0602\n",
      "Epoch 46/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3617 - accuracy: 0.1793 - val_loss: 4.6041 - val_accuracy: 0.0577\n",
      "Epoch 47/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3582 - accuracy: 0.1789 - val_loss: 4.6011 - val_accuracy: 0.0589\n",
      "Epoch 48/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.3533 - accuracy: 0.1793 - val_loss: 4.6051 - val_accuracy: 0.0579\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 49/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3540 - accuracy: 0.1786 - val_loss: 4.6082 - val_accuracy: 0.0573\n",
      "Epoch 50/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.3444 - accuracy: 0.1798 - val_loss: 4.6094 - val_accuracy: 0.0587\n",
      "Epoch 51/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3424 - accuracy: 0.1809 - val_loss: 4.6156 - val_accuracy: 0.0568\n",
      "Epoch 52/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3384 - accuracy: 0.1812 - val_loss: 4.6207 - val_accuracy: 0.0591\n",
      "Epoch 53/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3374 - accuracy: 0.1811 - val_loss: 4.6200 - val_accuracy: 0.0573\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 54/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.3318 - accuracy: 0.1810 - val_loss: 4.6267 - val_accuracy: 0.0567\n",
      "Epoch 55/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3302 - accuracy: 0.1817 - val_loss: 4.6269 - val_accuracy: 0.0565\n",
      "Epoch 56/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3305 - accuracy: 0.1817 - val_loss: 4.6299 - val_accuracy: 0.0584\n",
      "Epoch 57/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.3275 - accuracy: 0.1808 - val_loss: 4.6310 - val_accuracy: 0.0556\n",
      "Epoch 58/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3187 - accuracy: 0.1826 - val_loss: 4.6330 - val_accuracy: 0.0582\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 59/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.3169 - accuracy: 0.1834 - val_loss: 4.6400 - val_accuracy: 0.0554\n",
      "Epoch 60/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.3137 - accuracy: 0.1831 - val_loss: 4.6365 - val_accuracy: 0.0550\n",
      "Epoch 61/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.3110 - accuracy: 0.1820 - val_loss: 4.6431 - val_accuracy: 0.0547\n",
      "Epoch 62/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.3096 - accuracy: 0.1842 - val_loss: 4.6490 - val_accuracy: 0.0555\n",
      "Epoch 63/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.3046 - accuracy: 0.1819 - val_loss: 4.6519 - val_accuracy: 0.0538\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 64/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3041 - accuracy: 0.1832 - val_loss: 4.6558 - val_accuracy: 0.0543\n",
      "Epoch 65/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.3016 - accuracy: 0.1835 - val_loss: 4.6569 - val_accuracy: 0.0537\n",
      "Epoch 66/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.2961 - accuracy: 0.1853 - val_loss: 4.6631 - val_accuracy: 0.0538\n",
      "Epoch 67/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.2955 - accuracy: 0.1853 - val_loss: 4.6647 - val_accuracy: 0.0535\n",
      "Epoch 68/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2912 - accuracy: 0.1853 - val_loss: 4.6628 - val_accuracy: 0.0543\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 69/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.2868 - accuracy: 0.1853 - val_loss: 4.6646 - val_accuracy: 0.0521\n",
      "Epoch 70/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2865 - accuracy: 0.1862 - val_loss: 4.6694 - val_accuracy: 0.0532\n",
      "Epoch 71/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.2880 - accuracy: 0.1850 - val_loss: 4.6687 - val_accuracy: 0.0535\n",
      "Epoch 72/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.2870 - accuracy: 0.1855 - val_loss: 4.6720 - val_accuracy: 0.0552\n",
      "Epoch 73/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2827 - accuracy: 0.1861 - val_loss: 4.6778 - val_accuracy: 0.0557\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 74/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.2775 - accuracy: 0.1868 - val_loss: 4.6805 - val_accuracy: 0.0554\n",
      "Epoch 75/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.2750 - accuracy: 0.1859 - val_loss: 4.6812 - val_accuracy: 0.0547\n",
      "Epoch 76/100\n",
      "198166/198166 [==============================] - 20s 99us/step - loss: 3.2762 - accuracy: 0.1870 - val_loss: 4.6820 - val_accuracy: 0.0542\n",
      "Epoch 77/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.2751 - accuracy: 0.1867 - val_loss: 4.6869 - val_accuracy: 0.0544\n",
      "Epoch 78/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2679 - accuracy: 0.1878 - val_loss: 4.6877 - val_accuracy: 0.0537\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 79/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2633 - accuracy: 0.1875 - val_loss: 4.6946 - val_accuracy: 0.0535\n",
      "Epoch 80/100\n",
      "198166/198166 [==============================] - 20s 101us/step - loss: 3.2681 - accuracy: 0.1882 - val_loss: 4.6947 - val_accuracy: 0.0529\n",
      "Epoch 81/100\n",
      "198166/198166 [==============================] - 20s 100us/step - loss: 3.2671 - accuracy: 0.1874 - val_loss: 4.6967 - val_accuracy: 0.0541\n",
      "Epoch 82/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.2606 - accuracy: 0.1862 - val_loss: 4.6997 - val_accuracy: 0.0520\n",
      "Epoch 83/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.2622 - accuracy: 0.1885 - val_loss: 4.6999 - val_accuracy: 0.0523\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 84/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2603 - accuracy: 0.1881 - val_loss: 4.7007 - val_accuracy: 0.0527\n",
      "Epoch 85/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.2584 - accuracy: 0.1883 - val_loss: 4.7005 - val_accuracy: 0.0517\n",
      "Epoch 86/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2551 - accuracy: 0.1878 - val_loss: 4.7040 - val_accuracy: 0.0528\n",
      "Epoch 87/100\n",
      "198166/198166 [==============================] - 21s 106us/step - loss: 3.2517 - accuracy: 0.1880 - val_loss: 4.7132 - val_accuracy: 0.0513\n",
      "Epoch 88/100\n",
      "198166/198166 [==============================] - 21s 105us/step - loss: 3.2513 - accuracy: 0.1883 - val_loss: 4.7127 - val_accuracy: 0.0519\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 89/100\n",
      "198166/198166 [==============================] - 21s 105us/step - loss: 3.2565 - accuracy: 0.1877 - val_loss: 4.7132 - val_accuracy: 0.0518\n",
      "Epoch 90/100\n",
      "198166/198166 [==============================] - 21s 106us/step - loss: 3.2432 - accuracy: 0.1903 - val_loss: 4.7147 - val_accuracy: 0.0504\n",
      "Epoch 91/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2452 - accuracy: 0.1893 - val_loss: 4.7196 - val_accuracy: 0.0516\n",
      "Epoch 92/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2389 - accuracy: 0.1893 - val_loss: 4.7183 - val_accuracy: 0.0541\n",
      "Epoch 93/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2393 - accuracy: 0.1895 - val_loss: 4.7207 - val_accuracy: 0.0500\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 94/100\n",
      "198166/198166 [==============================] - 21s 107us/step - loss: 3.2354 - accuracy: 0.1900 - val_loss: 4.7251 - val_accuracy: 0.0519\n",
      "Epoch 95/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.2355 - accuracy: 0.1892 - val_loss: 4.7276 - val_accuracy: 0.0522\n",
      "Epoch 96/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.2337 - accuracy: 0.1898 - val_loss: 4.7277 - val_accuracy: 0.0522\n",
      "Epoch 97/100\n",
      "198166/198166 [==============================] - 21s 105us/step - loss: 3.2367 - accuracy: 0.1904 - val_loss: 4.7263 - val_accuracy: 0.0532\n",
      "Epoch 98/100\n",
      "198166/198166 [==============================] - 20s 102us/step - loss: 3.2381 - accuracy: 0.1907 - val_loss: 4.7317 - val_accuracy: 0.0500\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 99/100\n",
      "198166/198166 [==============================] - 21s 104us/step - loss: 3.2301 - accuracy: 0.1894 - val_loss: 4.7329 - val_accuracy: 0.0513\n",
      "Epoch 100/100\n",
      "198166/198166 [==============================] - 20s 103us/step - loss: 3.2318 - accuracy: 0.1893 - val_loss: 4.7359 - val_accuracy: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f518f426080>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model0.fit(x_train,\n",
    "              y_train,\n",
    "              epochs=100,\n",
    "              batch_size=1024,\n",
    "              validation_data=(x_validation, y_validation),\n",
    "              callbacks = callbacks)\n",
    "    \n",
    "# Load best weights\n",
    "#model = get_model('{}.hdf5'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zmw5QWv2N4S"
   },
   "outputs": [],
   "source": [
    "model0.load_weights('LSTM_256_100epoch.hdf5')\n",
    "model2.load_weights('LSTM_512_100epoch.hdf5')\n",
    "model4.load_weights('LSTM_128_100epoch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqwxvKwF6wgM"
   },
   "outputs": [],
   "source": [
    "    # Get top 3 predictions for each user\n",
    "    pred0 = model0.predict(x_test,batch_size=2048)\n",
    "    pred = pred0.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHvV6ZCIbVIk"
   },
   "outputs": [],
   "source": [
    "    pred2 = model2.predict(x_test,batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "th4QId6e1B0M"
   },
   "outputs": [],
   "source": [
    "    pred4 = model4.predict(x_test,batch_size=2048)\n",
    "    pred = pred4.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txkhLQJOXvFE"
   },
   "outputs": [],
   "source": [
    "def get_model1(path='',lr=0.005,dim):\n",
    "        adam = Adam(lr=lr)\n",
    "        inp = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "        x = Embedding(NB_WORDS,dim)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Bidirectional(GRU(dim))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(N_CATEGORIES, activation=\"softmax\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        if path != '':\n",
    "            model.load_weights(path)\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "model1=get_model1(dim=256)\n",
    "model3=get_model1(dim=512)\n",
    "model5=get_model1(dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hLO5eGk5YE1k",
    "outputId": "0a172233-fca9-4d51-e1d4-43e59d813945"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 198166 samples, validate on 10430 samples\n",
      "Epoch 1/100\n",
      "198166/198166 [==============================] - 43s 219us/step - loss: 5.4008 - accuracy: 0.0635 - val_loss: 6.5471 - val_accuracy: 0.0116\n",
      "Epoch 2/100\n",
      "198166/198166 [==============================] - 42s 213us/step - loss: 4.4447 - accuracy: 0.0983 - val_loss: 5.0297 - val_accuracy: 0.0842\n",
      "Epoch 3/100\n",
      "198166/198166 [==============================] - 42s 213us/step - loss: 4.0603 - accuracy: 0.1177 - val_loss: 4.4084 - val_accuracy: 0.0903\n",
      "Epoch 4/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 3.8357 - accuracy: 0.1302 - val_loss: 4.4501 - val_accuracy: 0.0827\n",
      "Epoch 5/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 3.6568 - accuracy: 0.1408 - val_loss: 4.4855 - val_accuracy: 0.0782\n",
      "Epoch 6/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 3.5180 - accuracy: 0.1485 - val_loss: 4.5146 - val_accuracy: 0.0718\n",
      "Epoch 7/100\n",
      "198166/198166 [==============================] - 42s 213us/step - loss: 3.3947 - accuracy: 0.1572 - val_loss: 4.5040 - val_accuracy: 0.0711\n",
      "Epoch 8/100\n",
      "198166/198166 [==============================] - 42s 212us/step - loss: 3.2924 - accuracy: 0.1648 - val_loss: 4.5798 - val_accuracy: 0.0593\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 9/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.8737 - accuracy: 0.2019 - val_loss: 4.6416 - val_accuracy: 0.0430\n",
      "Epoch 10/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.7475 - accuracy: 0.2059 - val_loss: 4.7311 - val_accuracy: 0.0382\n",
      "Epoch 11/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.6868 - accuracy: 0.2095 - val_loss: 4.7492 - val_accuracy: 0.0376\n",
      "Epoch 12/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.6275 - accuracy: 0.2148 - val_loss: 4.7825 - val_accuracy: 0.0330\n",
      "Epoch 13/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 2.5811 - accuracy: 0.2185 - val_loss: 4.8035 - val_accuracy: 0.0301\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 14/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.3093 - accuracy: 0.2536 - val_loss: 5.0010 - val_accuracy: 0.0176\n",
      "Epoch 15/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 2.2428 - accuracy: 0.2557 - val_loss: 5.0591 - val_accuracy: 0.0162\n",
      "Epoch 16/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 2.2072 - accuracy: 0.2567 - val_loss: 5.1101 - val_accuracy: 0.0149\n",
      "Epoch 17/100\n",
      "198166/198166 [==============================] - 42s 212us/step - loss: 2.1813 - accuracy: 0.2586 - val_loss: 5.1698 - val_accuracy: 0.0115\n",
      "Epoch 18/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 2.1528 - accuracy: 0.2604 - val_loss: 5.2057 - val_accuracy: 0.0112\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 19/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 2.0816 - accuracy: 0.2710 - val_loss: 5.3156 - val_accuracy: 0.0093\n",
      "Epoch 20/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 2.0560 - accuracy: 0.2732 - val_loss: 5.3337 - val_accuracy: 0.0100\n",
      "Epoch 21/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 2.0410 - accuracy: 0.2726 - val_loss: 5.3634 - val_accuracy: 0.0087\n",
      "Epoch 22/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 2.0279 - accuracy: 0.2745 - val_loss: 5.3585 - val_accuracy: 0.0069\n",
      "Epoch 23/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 2.0107 - accuracy: 0.2759 - val_loss: 5.4155 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 24/100\n",
      "198166/198166 [==============================] - 42s 212us/step - loss: 2.0008 - accuracy: 0.2754 - val_loss: 5.4375 - val_accuracy: 0.0066\n",
      "Epoch 25/100\n",
      "198166/198166 [==============================] - 42s 212us/step - loss: 1.9873 - accuracy: 0.2765 - val_loss: 5.4257 - val_accuracy: 0.0055\n",
      "Epoch 26/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 1.9774 - accuracy: 0.2770 - val_loss: 5.4468 - val_accuracy: 0.0056\n",
      "Epoch 27/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.9670 - accuracy: 0.2772 - val_loss: 5.4898 - val_accuracy: 0.0059\n",
      "Epoch 28/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.9607 - accuracy: 0.2775 - val_loss: 5.4785 - val_accuracy: 0.0054\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 29/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 1.9493 - accuracy: 0.2781 - val_loss: 5.5112 - val_accuracy: 0.0051\n",
      "Epoch 30/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.9440 - accuracy: 0.2778 - val_loss: 5.5274 - val_accuracy: 0.0040\n",
      "Epoch 31/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.9351 - accuracy: 0.2788 - val_loss: 5.5477 - val_accuracy: 0.0048\n",
      "Epoch 32/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 1.9275 - accuracy: 0.2787 - val_loss: 5.5771 - val_accuracy: 0.0040\n",
      "Epoch 33/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.9237 - accuracy: 0.2791 - val_loss: 5.5368 - val_accuracy: 0.0033\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 34/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.9116 - accuracy: 0.2808 - val_loss: 5.5561 - val_accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.9102 - accuracy: 0.2784 - val_loss: 5.6019 - val_accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.9020 - accuracy: 0.2800 - val_loss: 5.6026 - val_accuracy: 0.0032\n",
      "Epoch 37/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8962 - accuracy: 0.2802 - val_loss: 5.6129 - val_accuracy: 0.0033\n",
      "Epoch 38/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8917 - accuracy: 0.2800 - val_loss: 5.6682 - val_accuracy: 0.0037\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 39/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8866 - accuracy: 0.2799 - val_loss: 5.6564 - val_accuracy: 0.0035\n",
      "Epoch 40/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.8807 - accuracy: 0.2823 - val_loss: 5.6563 - val_accuracy: 0.0027\n",
      "Epoch 41/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.8829 - accuracy: 0.2784 - val_loss: 5.6401 - val_accuracy: 0.0026\n",
      "Epoch 42/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8739 - accuracy: 0.2800 - val_loss: 5.6491 - val_accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.8660 - accuracy: 0.2819 - val_loss: 5.7057 - val_accuracy: 0.0022\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 44/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8645 - accuracy: 0.2817 - val_loss: 5.6819 - val_accuracy: 0.0025\n",
      "Epoch 45/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.8648 - accuracy: 0.2820 - val_loss: 5.6693 - val_accuracy: 0.0030\n",
      "Epoch 46/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 1.8597 - accuracy: 0.2796 - val_loss: 5.6853 - val_accuracy: 0.0015\n",
      "Epoch 47/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8546 - accuracy: 0.2815 - val_loss: 5.7002 - val_accuracy: 0.0021\n",
      "Epoch 48/100\n",
      "198166/198166 [==============================] - 42s 211us/step - loss: 1.8483 - accuracy: 0.2805 - val_loss: 5.7097 - val_accuracy: 0.0024\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 49/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8440 - accuracy: 0.2815 - val_loss: 5.6943 - val_accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8383 - accuracy: 0.2836 - val_loss: 5.7242 - val_accuracy: 0.0017\n",
      "Epoch 51/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.8370 - accuracy: 0.2834 - val_loss: 5.7428 - val_accuracy: 0.0018\n",
      "Epoch 52/100\n",
      "198166/198166 [==============================] - 42s 209us/step - loss: 1.8350 - accuracy: 0.2822 - val_loss: 5.7148 - val_accuracy: 0.0016\n",
      "Epoch 53/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.8297 - accuracy: 0.2828 - val_loss: 5.7500 - val_accuracy: 0.0015\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 54/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8284 - accuracy: 0.2819 - val_loss: 5.7589 - val_accuracy: 0.0015\n",
      "Epoch 55/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8287 - accuracy: 0.2816 - val_loss: 5.7603 - val_accuracy: 0.0017\n",
      "Epoch 56/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8207 - accuracy: 0.2819 - val_loss: 5.7363 - val_accuracy: 0.0013\n",
      "Epoch 57/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8166 - accuracy: 0.2845 - val_loss: 5.8041 - val_accuracy: 0.0011\n",
      "Epoch 58/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.8187 - accuracy: 0.2812 - val_loss: 5.7825 - val_accuracy: 0.0018\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 59/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.8129 - accuracy: 0.2829 - val_loss: 5.7685 - val_accuracy: 8.6290e-04\n",
      "Epoch 60/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.8135 - accuracy: 0.2820 - val_loss: 5.7630 - val_accuracy: 0.0013\n",
      "Epoch 61/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.8088 - accuracy: 0.2844 - val_loss: 5.7718 - val_accuracy: 0.0013\n",
      "Epoch 62/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.8081 - accuracy: 0.2812 - val_loss: 5.8009 - val_accuracy: 0.0011\n",
      "Epoch 63/100\n",
      "198166/198166 [==============================] - 42s 209us/step - loss: 1.8033 - accuracy: 0.2829 - val_loss: 5.8498 - val_accuracy: 9.5877e-04\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 64/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7962 - accuracy: 0.2845 - val_loss: 5.8232 - val_accuracy: 6.7114e-04\n",
      "Epoch 65/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7967 - accuracy: 0.2839 - val_loss: 5.8294 - val_accuracy: 6.7114e-04\n",
      "Epoch 66/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7990 - accuracy: 0.2818 - val_loss: 5.7804 - val_accuracy: 5.7526e-04\n",
      "Epoch 67/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7961 - accuracy: 0.2841 - val_loss: 5.8335 - val_accuracy: 6.7114e-04\n",
      "Epoch 68/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7885 - accuracy: 0.2831 - val_loss: 5.8483 - val_accuracy: 0.0012\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 69/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7879 - accuracy: 0.2838 - val_loss: 5.8371 - val_accuracy: 0.0011\n",
      "Epoch 70/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7896 - accuracy: 0.2820 - val_loss: 5.7808 - val_accuracy: 9.5877e-04\n",
      "Epoch 71/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7842 - accuracy: 0.2834 - val_loss: 5.8251 - val_accuracy: 4.7939e-04\n",
      "Epoch 72/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7805 - accuracy: 0.2827 - val_loss: 5.8261 - val_accuracy: 7.6702e-04\n",
      "Epoch 73/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7831 - accuracy: 0.2830 - val_loss: 5.8330 - val_accuracy: 5.7526e-04\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 74/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7788 - accuracy: 0.2819 - val_loss: 5.9088 - val_accuracy: 6.7114e-04\n",
      "Epoch 75/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7758 - accuracy: 0.2827 - val_loss: 5.8482 - val_accuracy: 5.7526e-04\n",
      "Epoch 76/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7718 - accuracy: 0.2849 - val_loss: 5.8462 - val_accuracy: 5.7526e-04\n",
      "Epoch 77/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7723 - accuracy: 0.2828 - val_loss: 5.8564 - val_accuracy: 6.7114e-04\n",
      "Epoch 78/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7712 - accuracy: 0.2836 - val_loss: 5.8754 - val_accuracy: 6.7114e-04\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 79/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7691 - accuracy: 0.2838 - val_loss: 5.9106 - val_accuracy: 5.7526e-04\n",
      "Epoch 80/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7651 - accuracy: 0.2836 - val_loss: 5.8809 - val_accuracy: 5.7526e-04\n",
      "Epoch 81/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7663 - accuracy: 0.2826 - val_loss: 5.8560 - val_accuracy: 4.7939e-04\n",
      "Epoch 82/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7636 - accuracy: 0.2833 - val_loss: 5.8580 - val_accuracy: 3.8351e-04\n",
      "Epoch 83/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7594 - accuracy: 0.2851 - val_loss: 5.8551 - val_accuracy: 7.6702e-04\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 84/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7594 - accuracy: 0.2847 - val_loss: 5.8749 - val_accuracy: 5.7526e-04\n",
      "Epoch 85/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7596 - accuracy: 0.2827 - val_loss: 5.8536 - val_accuracy: 1.9175e-04\n",
      "Epoch 86/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7583 - accuracy: 0.2825 - val_loss: 5.9486 - val_accuracy: 4.7939e-04\n",
      "Epoch 87/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7507 - accuracy: 0.2840 - val_loss: 5.9592 - val_accuracy: 7.6702e-04\n",
      "Epoch 88/100\n",
      "198166/198166 [==============================] - 41s 207us/step - loss: 1.7538 - accuracy: 0.2818 - val_loss: 5.8576 - val_accuracy: 6.7114e-04\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 89/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7537 - accuracy: 0.2836 - val_loss: 5.9523 - val_accuracy: 6.7114e-04\n",
      "Epoch 90/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7509 - accuracy: 0.2844 - val_loss: 5.8867 - val_accuracy: 3.8351e-04\n",
      "Epoch 91/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7490 - accuracy: 0.2830 - val_loss: 5.9425 - val_accuracy: 6.7114e-04\n",
      "Epoch 92/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.7522 - accuracy: 0.2824 - val_loss: 5.9112 - val_accuracy: 4.7939e-04\n",
      "Epoch 93/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7439 - accuracy: 0.2848 - val_loss: 5.9255 - val_accuracy: 6.7114e-04\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 94/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7430 - accuracy: 0.2838 - val_loss: 5.9423 - val_accuracy: 4.7939e-04\n",
      "Epoch 95/100\n",
      "198166/198166 [==============================] - 41s 209us/step - loss: 1.7446 - accuracy: 0.2822 - val_loss: 5.8873 - val_accuracy: 6.7114e-04\n",
      "Epoch 96/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7395 - accuracy: 0.2830 - val_loss: 5.9506 - val_accuracy: 3.8351e-04\n",
      "Epoch 97/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7364 - accuracy: 0.2860 - val_loss: 5.9482 - val_accuracy: 4.7939e-04\n",
      "Epoch 98/100\n",
      "198166/198166 [==============================] - 42s 210us/step - loss: 1.7384 - accuracy: 0.2833 - val_loss: 5.8967 - val_accuracy: 4.7939e-04\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 99/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7401 - accuracy: 0.2823 - val_loss: 5.9002 - val_accuracy: 4.7939e-04\n",
      "Epoch 100/100\n",
      "198166/198166 [==============================] - 41s 208us/step - loss: 1.7337 - accuracy: 0.2852 - val_loss: 5.9221 - val_accuracy: 3.8351e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f51fc3a9630>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,\n",
    "              y_train,\n",
    "              epochs=100,\n",
    "              batch_size=1024,\n",
    "              validation_data=(x_validation, y_validation),\n",
    "              callbacks = callbacks\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NMLTwyrAbn6"
   },
   "outputs": [],
   "source": [
    "model1.load_weights('GRU_512_100epoch.hdf5')\n",
    "model3.load_weights('GRU_512_100epoch.hdf5')\n",
    "model5.load_weights('GRU_512_100epoch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQQg_mr5f_-3"
   },
   "outputs": [],
   "source": [
    "pred3 = model3.predict(x_test,batch_size=2048)\n",
    "pred = pred3.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OitNHRfVYei6"
   },
   "outputs": [],
   "source": [
    "pred1 = model1.predict(x_test,batch_size=2048)\n",
    "pred = pred1.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = model5.predict(x_test,batch_size=2048)\n",
    "pred = pred3.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQuNyg4wZe5R"
   },
   "outputs": [],
   "source": [
    "overall_pred=(pred0+pred1+pred2+pred3+pred4+pred5)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tO09eHQEZikI"
   },
   "outputs": [],
   "source": [
    "pred = overall_pred.argsort(axis=1)[:,-3:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G72rFKh1GR_0"
   },
   "outputs": [],
   "source": [
    "    # Write Predictions\n",
    "    df_list = []\n",
    "    for i in range(3):\n",
    "        test_11 = test_text[['user_id']]\n",
    "        test_11['user_sequence'] = test_11.user_id.astype(str) + '_'+str(i+11)\n",
    "        test_11['challenge'] = encoder.inverse_transform(pred[:,i])\n",
    "        df_list.append(test_11[['user_sequence','challenge']])\n",
    "    pd.concat(df_list).to_csv('Ensemble_512_256_128.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Mml5OohoKto"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AV_Recomm_DeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
